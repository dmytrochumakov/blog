<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/">
  <channel>
    <title>IOS on Dmytro&#39;s Blog</title>
    <link>http://localhost:1313/tags/ios/</link>
    <description>Recent content in IOS on Dmytro&#39;s Blog</description>
    <image>
      <title>Dmytro&#39;s Blog</title>
      <url>http://localhost:1313/images/papermod-cover.png</url>
      <link>http://localhost:1313/images/papermod-cover.png</link>
    </image>
    <generator>Hugo -- 0.123.3</generator>
    <language>en</language>
    <lastBuildDate>Wed, 31 Jul 2024 07:26:30 +0300</lastBuildDate>
    <atom:link href="http://localhost:1313/tags/ios/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>Optimizing iOS App Performance - Common Techniques</title>
      <link>http://localhost:1313/posts/optimizing-ios-app-performance-common-techniques/</link>
      <pubDate>Wed, 31 Jul 2024 07:26:30 +0300</pubDate>
      <guid>http://localhost:1313/posts/optimizing-ios-app-performance-common-techniques/</guid>
      <description>Introduction A well-performing application is the heart of a good user experience. If an application responds well, it helps attract more users and grow the business around it. On the other hand, if it performs poorly, it frustrates users and leads them to uninstall the app. To solve these issues, we need tools to monitor app behavior. Luckily for us, Xcode provides a list of tools that will help us resolve these problems.</description>
    </item>
    <item>
      <title>Implementing HealthKit in an iOS App</title>
      <link>http://localhost:1313/posts/implementing-healthkit-in-an-ios-app/</link>
      <pubDate>Fri, 26 Jul 2024 07:18:58 +0300</pubDate>
      <guid>http://localhost:1313/posts/implementing-healthkit-in-an-ios-app/</guid>
      <description>Introduction Previously, I worked with a healthcare app that used the HealthKit framework, but I did not get the opportunity to implement it myself. I decided to look into it and share what I found. In this article, I will focus on the steps to integrate HealthKit, write, and access its data.
Preparation Before we dive into implementation, I assume that you have an active Apple Developer account; without it, you will not be able to access the HealthKit Store.</description>
    </item>
    <item>
      <title>Implementing ChatGPT in an iOS App</title>
      <link>http://localhost:1313/posts/implementing-chatgpt-in-an-ios-app/</link>
      <pubDate>Sun, 21 Jul 2024 07:25:28 +0300</pubDate>
      <guid>http://localhost:1313/posts/implementing-chatgpt-in-an-ios-app/</guid>
      <description>Introduction I haven&amp;rsquo;t had the opportunity to build a chatbot before. This topic was trending some time ago, and I always wanted to implement it myself. In this article, I will focus on the steps you need to know to successfully build and run a chatbot application.
First Step The first step is to add the OpenAI dependency to your project:
.package(url: &amp;#34;https://github.com/MacPaw/OpenAI.git&amp;#34;, branch: &amp;#34;main&amp;#34;) dependencies: [ .byNameItem( name: &amp;#34;OpenAI&amp;#34;, condition: .</description>
    </item>
    <item>
      <title>Implementing Apple Sign-In to an iOS App</title>
      <link>http://localhost:1313/posts/implementing-apple-sign-in-to-an-ios-app/</link>
      <pubDate>Thu, 18 Jul 2024 07:26:13 +0300</pubDate>
      <guid>http://localhost:1313/posts/implementing-apple-sign-in-to-an-ios-app/</guid>
      <description>Introduction The Apple Sign-In feature is very helpful and offers users login functionality with one click. It could be highly beneficial from a business perspective to attract more potential customers by providing easy and secure access to application functionality. In this article, I will focus on how to implement Apple Sign-In.
Before implementation, letâ€™s set up the necessary options to be able to run the app without errors.
Add Sign in with Apple Capability to the project &amp;#x1f4dd; Before testing on the simulator, you need to be signed in to an account with enabled two-factor authentication.</description>
    </item>
    <item>
      <title>Scanning NFC tags using CoreNFC in an iOS app</title>
      <link>http://localhost:1313/posts/scanning-nfc-tags-using-corenfc-in-an-ios-app/</link>
      <pubDate>Fri, 12 Jul 2024 07:27:51 +0300</pubDate>
      <guid>http://localhost:1313/posts/scanning-nfc-tags-using-corenfc-in-an-ios-app/</guid>
      <description>Introduction I never had a chance to work with NFC (Near Field Communication), but I have always been curious to find out how it works. In this article, I will focus on scanning NFC tags using CoreNFC with NFCNDEFReaderSession.
Preparation Before we begin, let&amp;rsquo;s add the necessary objects:
Near Field Communication Tag Reading capability to the project. Privacy - NFC Scan Usage Description key to Info.plist. Near Field Communication Tag Reader Session Formats to the entitlements file.</description>
    </item>
    <item>
      <title>Scanning for peripheral devices using BLE in an iOS app</title>
      <link>http://localhost:1313/posts/scanning-for-peripheral-devices-using-ble-in-an-ios-app/</link>
      <pubDate>Wed, 10 Jul 2024 07:27:14 +0300</pubDate>
      <guid>http://localhost:1313/posts/scanning-for-peripheral-devices-using-ble-in-an-ios-app/</guid>
      <description>Introduction I had the chance to work on a project where communication via BLE was at the heart of the project.
Before adding any code to application, I always asked myself about two scenarios:
The first scenario is when the device acts as a central device while searching for and connecting to peripheral devices. The second scenario is when the device acts as a peripheral device by using CBCharacteristic and changes its value.</description>
    </item>
    <item>
      <title>Battery Performance Testing for iOS App</title>
      <link>http://localhost:1313/posts/battery-performance-testing-for-ios-app/</link>
      <pubDate>Sun, 07 Jul 2024 07:25:40 +0300</pubDate>
      <guid>http://localhost:1313/posts/battery-performance-testing-for-ios-app/</guid>
      <description>Introduction Working with batteries on iOS devices for large applications has always been tricky. The amount of energy consumed by the screen, location services, network calls, processing, background tasks, etc., is significant. From a developer&amp;rsquo;s perspective, it seems complicated, but Xcode provides tools to address this problem.
To find the issue, you need to open Xcode and go to the Debug Navigator.
In the Debug Navigator, you will see the Energy Impact gauge.</description>
    </item>
    <item>
      <title>Creating a 2D Space Game for iOS Using SpriteKit - Part 2</title>
      <link>http://localhost:1313/posts/creating-2d-space-game-for-ios-using-spritekit-part-2/</link>
      <pubDate>Wed, 03 Jul 2024 06:39:04 +0300</pubDate>
      <guid>http://localhost:1313/posts/creating-2d-space-game-for-ios-using-spritekit-part-2/</guid>
      <description>Introduction In the previous chapter, I started talking about the video game creation process, from project setup to adding the background. Now, I&amp;rsquo;m going to add the player and physics to it.
You can download the project here.
First Step The first step is to initialize player using SKSpriteNode, set up player.position, and add player as a child node.
SKSpriteNode - is an onscreen graphical element that can be initialized from an image or a solid color.</description>
    </item>
    <item>
      <title>Creating a 2D Space Game for iOS Using SpriteKit - Part 1</title>
      <link>http://localhost:1313/posts/creating-2d-space-game-for-ios-using-spritekit-part-1/</link>
      <pubDate>Fri, 28 Jun 2024 07:18:59 +0300</pubDate>
      <guid>http://localhost:1313/posts/creating-2d-space-game-for-ios-using-spritekit-part-1/</guid>
      <description>Introduction I have never tried creating a game before; it feels like magic to me. I know that games have an enormous amount of underlying layers of abstractions and tools such as game engines, rendering, and so on. I have always been eager to learn at least 1% of the game creation process. In this article, I&amp;rsquo;m going to explore step-by-step instructions for creating a game for the iOS platform using SpriteKit.</description>
    </item>
    <item>
      <title>Testing push notifications locally in an iOS app</title>
      <link>http://localhost:1313/posts/testing-push-notifications-locally-in-an-ios-app/</link>
      <pubDate>Wed, 19 Jun 2024 07:13:19 +0300</pubDate>
      <guid>http://localhost:1313/posts/testing-push-notifications-locally-in-an-ios-app/</guid>
      <description>Introduction I always wondered how I could automate testing the push notification process. Even when Apple introduced the possibility of dragging a configured file to the simulator to display a notification, it is still a manual process. I&amp;rsquo;ll skip testing via the terminal because I think it takes more time than using an APNS file or the RocketSim app.
Before I was first introduced to the RocketSim app, I used an APNS file for testing push notifications.</description>
    </item>
    <item>
      <title>Adding Push Notifications to an iOS App</title>
      <link>http://localhost:1313/posts/adding-push-notifications-to-an-ios-app/</link>
      <pubDate>Fri, 14 Jun 2024 07:29:01 +0300</pubDate>
      <guid>http://localhost:1313/posts/adding-push-notifications-to-an-ios-app/</guid>
      <description>Introduction If you start a project from scratch, you need to always create some kind of service like PushNotificationService that will be responsible for handling push notification events. In this article, I want to explore a simple implementation of PushNotificationService to be able to reuse and customize it in future projects.
First Step The first step is to add the Push Notifications capability to your project. Go to your project -&amp;gt; Signing &amp;amp; Capabilities -&amp;gt; Tap + Capability -&amp;gt; Search for Push Notifications.</description>
    </item>
    <item>
      <title>Caching data using NSCache in iOS</title>
      <link>http://localhost:1313/posts/caching-data-using-nscache-in-ios/</link>
      <pubDate>Wed, 05 Jun 2024 07:13:58 +0300</pubDate>
      <guid>http://localhost:1313/posts/caching-data-using-nscache-in-ios/</guid>
      <description>Introduction I was curious about caching data using NSCache for an iOS app. So, I did some digging. Here is what I found:
Quick Overview NSCache helps store data in memory. When the application gets killed, it frees memory; itâ€™s not persisted on disk. Storing data is carried out using a key-value pair mechanism like Dictionary. You can set automatic eviction to delete objects automatically. NSCache has multi-platform support: iOS, iPadOS, watchOS, macOS, and tvOS.</description>
    </item>
    <item>
      <title>Accessibility iOS SwiftUI</title>
      <link>http://localhost:1313/posts/accessibility-ios-swiftui/</link>
      <pubDate>Sun, 02 Jun 2024 09:04:06 +0300</pubDate>
      <guid>http://localhost:1313/posts/accessibility-ios-swiftui/</guid>
      <description>Introduction Previously, I posted about Accessibility for UIKit. The idea behind this post is to find differences between UIKit Accessibility and SwiftUI features.
Similarities: Both UIKit and SwiftUI have accessibilityLabel and accessibilityHints APIs.
Differences: To use dynamic type for fonts, you need additional modifiers in SwiftUI. struct ScaledFont: ViewModifier { @Environment(\.sizeCategory) var sizeCategory var name: String var size: Double func body(content: Content) -&amp;gt; some View { let scaledSize = UIFontMetrics.default.scaledValue(for: size) return content.</description>
    </item>
    <item>
      <title>Accessibility iOS UIKit</title>
      <link>http://localhost:1313/posts/accessibility-ios-uikit/</link>
      <pubDate>Thu, 30 May 2024 07:04:49 +0300</pubDate>
      <guid>http://localhost:1313/posts/accessibility-ios-uikit/</guid>
      <description>Introduction I was curious to find out how to make an application more accessible. You can look at popular applications like YouTube or Netflix; they all have accessibility features like VoiceOver and dynamic fonts. I decided to create this example for a fruit calorie counter. It contains a list of fruits with the fruit name, fruit calories, and a favorite button.
Where to Start Before diving into implementation details, I want to highlight some information about the existing accessibility features and what I will be focusing on.</description>
    </item>
    <item>
      <title>Text To Speech iOS</title>
      <link>http://localhost:1313/posts/text-to-speech-ios/</link>
      <pubDate>Fri, 24 May 2024 07:52:07 +0300</pubDate>
      <guid>http://localhost:1313/posts/text-to-speech-ios/</guid>
      <description>Introduction I was eager to learn how converting Text To Speech works in iOS. Here is what I discovered:
First Step The first step is to add AVSpeechSynthesizer, an object that produces synthesized speech from text utterances.
@State private var speechSynthesizer = AVSpeechSynthesizer() Second Step The second step is to add AVSpeechUtterance, an object that encapsulates the text for speech synthesis.
private var utterance: AVSpeechUtterance { let inputMessage = &amp;#34;Hello world!</description>
    </item>
    <item>
      <title>Speech To Text iOS</title>
      <link>http://localhost:1313/posts/speech-to-text-ios/</link>
      <pubDate>Thu, 23 May 2024 08:37:45 +0300</pubDate>
      <guid>http://localhost:1313/posts/speech-to-text-ios/</guid>
      <description>Introduction I always wanted an iOS app that would allow me to economize my time by converting speech to text. I know this option is built into the keyboard, but you first need to click the text field, then tap on the microphone, and finally speak. I wanted a one-click option with the possibility to integrate it into all my daily routines. Here is what I discovered:
First Step The first step is to request authorization to access the device&amp;rsquo;s microphone using the Privacy - Speech Recognition Usage Description key and the Privacy - Microphone Usage Description key.</description>
    </item>
    <item>
      <title>Implementing GraphQL in an iOS application</title>
      <link>http://localhost:1313/posts/implementing-graphql-in-an-ios-application/</link>
      <pubDate>Wed, 15 May 2024 07:13:39 +0300</pubDate>
      <guid>http://localhost:1313/posts/implementing-graphql-in-an-ios-application/</guid>
      <description>Introduction I previously never had a chance to work with GraphQL. I was excited to learn when to apply this technology, what tools I can use, and how I can implement it. Hereâ€™s what I found:
For testing, I used the Star Wars GraphQL API with AllFilmsQuery:
query AllFilmsQuery { allFilms { films { title director created producers releaseDate } } } I requested allFilms with title, director, created, producers, and releaseDate information.</description>
    </item>
    <item>
      <title>Building Dynamic Island for Video Streaming App</title>
      <link>http://localhost:1313/posts/building-dynamic-island-for-video-streaming-app/</link>
      <pubDate>Mon, 06 May 2024 07:35:52 +0300</pubDate>
      <guid>http://localhost:1313/posts/building-dynamic-island-for-video-streaming-app/</guid>
      <description>Introduction I was curious about how to add Dynamic Island and implement it into a Video Streaming App. Here are a few steps on how you can achieve this.
Caveats Debugging Dynamic Island can be a bit tricky; it only works when the main app is running. If you try to run it separately, you will encounter the error SendProcessControlEvent:toPid: encountered an error: Error Domain=com.apple.dt.deviceprocesscontrolservice Code=8 &amp;quot;Failed to show Widget&amp;quot;. The solution is to configure live activities and run them through the main app.</description>
    </item>
    <item>
      <title>Building Video Streaming Widget for iOS App</title>
      <link>http://localhost:1313/posts/building-video-streaming-widget-for-ios-app/</link>
      <pubDate>Sun, 05 May 2024 07:20:29 +0300</pubDate>
      <guid>http://localhost:1313/posts/building-video-streaming-widget-for-ios-app/</guid>
      <description>Introduction I was exploring the idea of creating a YouTube-like widget for the lock screen on iOS devices. It wasn&amp;rsquo;t easy because most articles on the Internet discussed general implementations, such as for a coffee shop or a to-do list. Even when I found some similar versions, the project wouldn&amp;rsquo;t compile. I made the decision to approach it my way, so here&amp;rsquo;s what I found out:
Caveats After being stuck for two or more hours without understanding why, after tapping on a button, I wasn&#39;t able to receive a callback from it and the widget always opened the main iOS app, I realized that I forgot to add AppIntent - without it, you can&amp;rsquo;t handle actions for iOS 17.</description>
    </item>
    <item>
      <title>Building Video Streaming iOS App</title>
      <link>http://localhost:1313/posts/building-video-streaming-ios-app/</link>
      <pubDate>Fri, 03 May 2024 07:34:56 +0300</pubDate>
      <guid>http://localhost:1313/posts/building-video-streaming-ios-app/</guid>
      <description>Introduction I was looking for a way to add a video player to my iOS app that could be able to play remote videos.
Caveats Problem I found that you can&amp;rsquo;t open Vimeo or Youtube videos because of AVFoundationErrorDomain Code=-11850 &amp;quot;Operation Stopped&amp;quot; UserInfo={NSLocalizedFailureReason=The server is not correctly configured Domain=NSOSStatusErrorDomain Code=-12939 error. I donâ€™t know exactly what this means, but I&amp;rsquo;m speculating it&amp;rsquo;s related to some protection.
Solution My solution was to find another video that is not related to those platforms.</description>
    </item>
    <item>
      <title>Building Group Chat using WebSockets</title>
      <link>http://localhost:1313/posts/building-group-chat-using-websockets/</link>
      <pubDate>Thu, 02 May 2024 15:15:14 +0300</pubDate>
      <guid>http://localhost:1313/posts/building-group-chat-using-websockets/</guid>
      <description>Introduction I never had a chance to work with WebSockets, so I decided to take a look and create a group chat. Here&amp;rsquo;s what I discovered:
To be able to send and receive messages, you need to create an interface for communication between a server and your application. In my case, I chose sendMessage and receiveMessage methods. For the server-side, I chose Node.js. For the iOS application, I chose the Socket.</description>
    </item>
    <item>
      <title>iOS AR App: Experience 3D Guitar</title>
      <link>http://localhost:1313/posts/ios-ar-app-experience-3d-guitar/</link>
      <pubDate>Wed, 01 May 2024 15:57:54 +0300</pubDate>
      <guid>http://localhost:1313/posts/ios-ar-app-experience-3d-guitar/</guid>
      <description>Introduction I was searching for an AR implementation of a 3D guitar inside an iOS app. Here&amp;rsquo;s what I discovered:
First Step The first step is not related to building the app. Before that you need to create a project using the Reality Composer Pro app (you can find it through Spotlight search).
Second Step After that, you need to visit https://developer.apple.com/augmented-reality/quick-look/ and download one of the USDZ files. In my case, I chose the 3D guitar.</description>
    </item>
  </channel>
</rss>
